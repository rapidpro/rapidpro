# -*- coding: utf-8 -*-
# Generated by Django 1.11.2 on 2017-11-02 15:39
from __future__ import absolute_import, division, print_function, unicode_literals

import json
import time
import os

from datetime import timedelta
from django.db import migrations, transaction
from django.db.models import Prefetch
from django.utils import timezone
from django_redis import get_redis_connection
from temba.utils import chunk_list
from temba.utils.management.commands.migrate_flows import migrate_flows

# these are called out here because we can't reference the real FlowRun in this migration
PATH_NODE_UUID = 'node_uuid'
PATH_ARRIVED_ON = 'arrived_on'
PATH_EXIT_UUID = 'exit_uuid'
PATH_MAX_STEPS = 100

CACHE_KEY_HIGHPOINT = 'path_mig_highpoint'
CACHE_KEY_MAX_RUN_ID = 'path_mig_max_run_id'


def backfill_flowrun_path(ActionSet, FlowRun, FlowStep):
    cache = get_redis_connection()

    # start by ensuring all flows are at a minimum version
    if not migrate_flows('10.4'):
        raise ValueError("Migration can't proceed because some flows couldn't be migrated")

    # get all flow action sets
    action_sets = list(ActionSet.objects.filter(flow__is_active=True))
    if not action_sets:
        return

    print("Found %d flow action sets..." % len(action_sets))

    # make map of action set node UUIDs to their exit UUIDs
    action_set_uuid_to_exit = {a.uuid: a.exit_uuid for a in action_sets if a.exit_uuid}

    if len(action_sets) != len(action_set_uuid_to_exit):
        raise ValueError(
            "Found actionsets without exit_uuids, use migrate_flows command to migrate these flows forward"
        )

    # are we running on just a partition of the runs?
    partition = os.environ.get('PARTITION')
    if partition is not None:
        partition = int(partition)
        if partition < 0 or partition > 3:
            raise ValueError("Partition must be 0-3")

        print("Migrating runs in partition %d" % partition)

    # has this migration been run before but didn't complete?
    highpoint = None
    if partition is not None:
        highpoint = cache.get(CACHE_KEY_HIGHPOINT + (':%d' % partition))
    if highpoint is None:
        highpoint = cache.get(CACHE_KEY_HIGHPOINT)

    highpoint = 0 if highpoint is None else int(highpoint)

    max_run_id = cache.get(CACHE_KEY_MAX_RUN_ID)
    if max_run_id is None:
        print("Getting if of last run which will need migrated...")
        max_run = FlowRun.objects.filter(flow__is_active=True).order_by('-id').first()
        if max_run:
            max_run_id = max_run.id
            cache.set(CACHE_KEY_MAX_RUN_ID, max_run_id, 60 * 60 * 24 * 7)
    else:
        max_run_id = int(max_run_id)

    # get all flow runs we're going to migrate
    runs = FlowRun.objects.filter(flow__is_active=True).only('id').order_by('id')

    if highpoint:
        print("Resuming from previous highpoint at run #%d" % highpoint)
        runs = runs.filter(id__gt=highpoint)

    if max_run_id:
        print("Migrating runs up to run #%d" % max_run_id)
        runs = runs.filter(id__lte=max_run_id)

    remaining_estimate = max_run_id - highpoint
    print("Estimated %d runs need to be migrated" % remaining_estimate)

    num_updated = 0
    num_trimmed = 0
    start = None

    # we want to prefetch steps with each flow run, in chronological order
    steps_prefetch = Prefetch('steps', queryset=FlowStep.objects.only('step_uuid', 'step_type', 'rule_uuid', 'arrived_on').order_by('id'))

    for run_batch in chunk_list(runs.using('direct').iterator(), 1000):
        # first call is gonna take a while to complete the query on the db, so start timer after that
        if start is None:
            start = time.time()

        with transaction.atomic():
            if partition is not None:
                run_ids = [r.id for r in run_batch if ((r.id + partition) % 4 == 0)]
            else:
                run_ids = [r.id for r in run_batch]

            batch = FlowRun.objects.filter(id__in=run_ids).order_by('id').prefetch_related(steps_prefetch)

            for run in batch:
                path = []
                for step in run.steps.all():
                    step_dict = {PATH_NODE_UUID: step.step_uuid, PATH_ARRIVED_ON: step.arrived_on.isoformat()}
                    if step.step_type == 'R':
                        step_dict[PATH_EXIT_UUID] = step.rule_uuid
                    else:
                        exit_uuid = action_set_uuid_to_exit.get(step.step_uuid)
                        if exit_uuid:
                            step_dict[PATH_EXIT_UUID] = exit_uuid

                    path.append(step_dict)

                # trim path if necessary
                if len(path) > PATH_MAX_STEPS:
                    path = path[len(path) - PATH_MAX_STEPS:]
                    num_trimmed += 1

                run.path = json.dumps(path)
                run.save(update_fields=('path',))

                highpoint = run.id
                if partition is not None:
                    cache.set(CACHE_KEY_HIGHPOINT + (":%d" % partition), str(run.id), 60 * 60 * 24 * 7)
                else:
                    cache.set(CACHE_KEY_HIGHPOINT, str(run.id), 60 * 60 * 24 * 7)

        num_updated += len(batch)
        updated_per_sec = num_updated / (time.time() - start)

        # figure out estimated time remaining
        num_remaining = ((max_run_id - highpoint) // 4) if partition is not None else (max_run_id - highpoint)
        time_remaining = num_remaining / updated_per_sec
        finishes = timezone.now() + timedelta(seconds=time_remaining)
        status = " > Updated %d runs of ~%d (%2.2f per sec) Est finish: %s" % (num_updated, remaining_estimate, updated_per_sec, finishes)

        if partition is not None:
            status += ' [PARTITION %d]' % partition

        print(status)

    print("Run path migration completed in %d mins. %d paths were trimmed" % ((int(time.time() - start) // 60), num_trimmed))


def apply_manual():
    from temba.flows.models import ActionSet, FlowRun, FlowStep
    backfill_flowrun_path(ActionSet, FlowRun, FlowStep)


def apply_as_migration(apps, schema_editor):
    ActionSet = apps.get_model('flows', 'ActionSet')
    FlowRun = apps.get_model('flows', 'FlowRun')
    FlowStep = apps.get_model('flows', 'FlowStep')
    backfill_flowrun_path(ActionSet, FlowRun, FlowStep)


class Migration(migrations.Migration):

    dependencies = [
        ('flows', '0126_flowrun_path'),
    ]

    operations = [
        migrations.RunPython(apply_as_migration)
    ]
