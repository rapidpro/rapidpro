# Generated by Django 1.11.6 on 2017-12-18 20:16

import json
import time
from array import array
from datetime import timedelta

from django_redis import get_redis_connection

from django.db import migrations, transaction
from django.utils import timezone

from temba.utils import chunk_list
from temba.utils.dates import str_to_datetime

CACHE_KEY_HIGHPOINT = "res_fix_mig_highpoint"


def fix_value_results(FlowRun, RuleSet, Value):
    cache = get_redis_connection()

    # make a map of ruleset IDs to UUIDs
    ruleset_id_to_uuid = {r.id: r.uuid for r in RuleSet.objects.all()}
    if not ruleset_id_to_uuid:
        return

    # has this migration been run before but didn't complete?
    highpoint = cache.get(CACHE_KEY_HIGHPOINT)
    highpoint = 0 if highpoint is None else int(highpoint)

    # problematic ruleset values are those which have a decimal and datetime value, as this implies that the input
    # was numeric, but was still erroneously parsed as a datetime
    values = Value.objects.exclude(decimal_value=None).exclude(datetime_value=None).exclude(run=None)

    # get all flow runs we need to fix
    run_ids = values.values_list("run_id", flat=True).order_by("run_id").distinct("run_id")

    if highpoint:
        print("Resuming from previous highpoint at run #%d" % highpoint)
        run_ids = run_ids.filter(id__gt=highpoint)

    run_ids = array(str("l"), run_ids)

    print("Total of %d runs need to be fixed" % len(run_ids))

    num_fixed = 0
    start = time.time()

    for id_batch in chunk_list(run_ids, 1000):
        with transaction.atomic():
            batch = (
                FlowRun.objects.filter(id__in=id_batch).order_by("id").select_related("org").prefetch_related("values")
            )

            for run in batch:
                day_first = run.org.date_format == "D"

                # find result values with which are no longer parsed as dates
                no_longer_dates = {}
                for v in run.values.all():
                    parsed_new = str_to_datetime(v.string_value, tz=run.org.timezone, dayfirst=day_first)
                    if not parsed_new and v.datetime_value:
                        no_longer_dates[ruleset_id_to_uuid[v.ruleset_id]] = v.string_value

                if no_longer_dates:
                    results = json.loads(run.results) if run.results else {}
                    for key, result in results.items():
                        node_uuid = result["node_uuid"]
                        if node_uuid in no_longer_dates:
                            result["value"] = no_longer_dates[node_uuid]

                    run.results = json.dumps(results)
                    run.save(update_fields=("results",))

                cache.set(CACHE_KEY_HIGHPOINT, str(run.id), 60 * 60 * 24 * 7)
                num_fixed += 1

        fixed_per_sec = num_fixed / (time.time() - start)

        # figure out estimated time remaining
        num_remaining = len(run_ids) - highpoint
        time_remaining = num_remaining / fixed_per_sec
        finishes = timezone.now() + timedelta(seconds=time_remaining)
        status = " > Updated %d runs of ~%d (%2.2f per sec) Est finish: %s" % (
            num_fixed,
            len(run_ids),
            fixed_per_sec,
            finishes,
        )
        print(status)

    print("Run results fix migration completed in %d mins" % (int(time.time() - start) // 60))


def apply_manual():
    from temba.flows.models import FlowRun, RuleSet
    from temba.values.models import Value

    fix_value_results(FlowRun, RuleSet, Value)


def apply_as_migration(apps, schema_editor):
    FlowRun = apps.get_model("flows", "FlowRun")
    RuleSet = apps.get_model("flows", "RuleSet")
    Value = apps.get_model("values", "Value")
    fix_value_results(FlowRun, RuleSet, Value)


class Migration(migrations.Migration):

    dependencies = [("flows", "0138_path_trigger_fix")]

    operations = [migrations.RunPython(apply_as_migration)]
